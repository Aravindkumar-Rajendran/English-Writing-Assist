{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWYdeza29EYaLScWrPWh+m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindkumar-Rajendran/spell-correction-model/blob/main/spell_check_and_correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "G_2qgu5mgIwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets available for spell correction task are very few.\n",
        "\n",
        "https://paperswithcode.com/task/spelling-correction#datasets  \n",
        "https://www.kaggle.com/datasets/bittlingmayer/spelling?select=wikipedia.txt  \n",
        "https://github.com/neuspell/neuspell/tree/master/data/traintest  \n",
        "\n"
      ],
      "metadata": {
        "id": "NG8FU6xXgQ_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Github typo corpus dataset\n",
        "\n",
        "https://github.com/mhagiwara/github-typo-corpus\n",
        "\n",
        "Dataset download url: https://github-typo-corpus.s3.amazonaws.com/data/github-typo-corpus.v1.0.0.jsonl.gz\n"
      ],
      "metadata": {
        "id": "r8-rwFnnomK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx6fVLva6wFU",
        "outputId": "a57a9a50-45fe-4a7f-9e66-b26bece6f5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-19 16:05:09--  https://github-typo-corpus.s3.amazonaws.com/data/github-typo-corpus.v1.0.0.jsonl.gz\n",
            "Resolving github-typo-corpus.s3.amazonaws.com (github-typo-corpus.s3.amazonaws.com)... 54.231.130.17\n",
            "Connecting to github-typo-corpus.s3.amazonaws.com (github-typo-corpus.s3.amazonaws.com)|54.231.130.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43769081 (42M) [application/x-gzip]\n",
            "Saving to: ‘github-typo-corpus.v1.0.0.jsonl.gz’\n",
            "\n",
            "github-typo-corpus. 100%[===================>]  41.74M  29.2MB/s    in 1.4s    \n",
            "\n",
            "2022-10-19 16:05:11 (29.2 MB/s) - ‘github-typo-corpus.v1.0.0.jsonl.gz’ saved [43769081/43769081]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github-typo-corpus.s3.amazonaws.com/data/github-typo-corpus.v1.0.0.jsonl.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbn-z0I0ozwy",
        "outputId": "ccf6b562-2788-492e-bf04-7ad4afd6dc12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "github-typo-corpus.v1.0.0.jsonl.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d github-typo-corpus.v1.0.0.jsonl.gz"
      ],
      "metadata": {
        "id": "9QE8DBCapDRG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "typo_data = pd.read_json(\"github-typo-corpus.v1.0.0.jsonl\", lines=True)"
      ],
      "metadata": {
        "id": "StTprWFNpKRx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "typo_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1nmj9ed7pkVO",
        "outputId": "7a4b70f9-b1ad-488e-bc6b-6b53bb40435d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                repo  \\\n",
              "0  https://github.com/abacritt/angularx-social-login   \n",
              "1  https://github.com/abacritt/angularx-social-login   \n",
              "2                    https://github.com/abahmed/Deer   \n",
              "3                    https://github.com/abakan/ablog   \n",
              "4                    https://github.com/abakan/ablog   \n",
              "\n",
              "                                     commit  \\\n",
              "0  d4c912f5ccd70c81f424fadbf1fe1a2ecb942f07   \n",
              "1  8beb5a5ebee0882142541dc84c004f6ce3165f94   \n",
              "2  44781b8842c7e647d1f5d2417d21244e815c5eec   \n",
              "3  1cee106975e3137cb9a667729e832cc9494f0692   \n",
              "4  4e11caf1f7ebe611ffb08f8a6909ac6752d784cd   \n",
              "\n",
              "                               message  \\\n",
              "0                           Fix typo\\n   \n",
              "1  fix typo\\n\\nfix typo in firstname\\n   \n",
              "2                fixed typo (#263)\\n\\n   \n",
              "3                        Fixed typo.\\n   \n",
              "4                         Fixed typo\\n   \n",
              "\n",
              "                                               edits  \n",
              "0  [{'src': {'text': '            IN.User.authori...  \n",
              "1  [{'src': {'text': '                    user.em...  \n",
              "2  [{'src': {'text': ' :de:             | Deutsch...  \n",
              "3  [{'src': {'text': '        :nocoments:', 'path...  \n",
              "4  [{'src': {'text': '   You can disable comments...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2450a99d-6943-4c2a-b392-220cd8afebda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo</th>\n",
              "      <th>commit</th>\n",
              "      <th>message</th>\n",
              "      <th>edits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://github.com/abacritt/angularx-social-login</td>\n",
              "      <td>d4c912f5ccd70c81f424fadbf1fe1a2ecb942f07</td>\n",
              "      <td>Fix typo\\n</td>\n",
              "      <td>[{'src': {'text': '            IN.User.authori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://github.com/abacritt/angularx-social-login</td>\n",
              "      <td>8beb5a5ebee0882142541dc84c004f6ce3165f94</td>\n",
              "      <td>fix typo\\n\\nfix typo in firstname\\n</td>\n",
              "      <td>[{'src': {'text': '                    user.em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://github.com/abahmed/Deer</td>\n",
              "      <td>44781b8842c7e647d1f5d2417d21244e815c5eec</td>\n",
              "      <td>fixed typo (#263)\\n\\n</td>\n",
              "      <td>[{'src': {'text': ' :de:             | Deutsch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://github.com/abakan/ablog</td>\n",
              "      <td>1cee106975e3137cb9a667729e832cc9494f0692</td>\n",
              "      <td>Fixed typo.\\n</td>\n",
              "      <td>[{'src': {'text': '        :nocoments:', 'path...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://github.com/abakan/ablog</td>\n",
              "      <td>4e11caf1f7ebe611ffb08f8a6909ac6752d784cd</td>\n",
              "      <td>Fixed typo\\n</td>\n",
              "      <td>[{'src': {'text': '   You can disable comments...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2450a99d-6943-4c2a-b392-220cd8afebda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2450a99d-6943-4c2a-b392-220cd8afebda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2450a99d-6943-4c2a-b392-220cd8afebda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "idx = random.randint(0, len(typo_data))\n",
        "typo_data['edits'][idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh75lGKFqST3",
        "outputId": "5738ce2a-0443-489d-dfe2-be16355402a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'src': {'text': 'If you\\'re unable to use promises or other supported async objects, you may enable \"callback mode\" by defining your test with `test.cb([title\\', fn)`. Tests declared this way **must** be manually ended with `t.end()`. This mode is mainly intended for testing callback-style APIs.',\n",
              "   'path': 'readme.md',\n",
              "   'lang': 'eng',\n",
              "   'ppl': 5.8147712336705375},\n",
              "  'tgt': {'text': 'If you\\'re unable to use promises or other supported async objects, you may enable \"callback mode\" by defining your test with `test.cb([title], fn)`. Tests declared this way **must** be manually ended with `t.end()`. This mode is mainly intended for testing callback-style APIs.',\n",
              "   'path': 'readme.md',\n",
              "   'lang': 'eng',\n",
              "   'ppl': 5.74987434397607},\n",
              "  'prob_typo': 0.9211678380303181,\n",
              "  'is_typo': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edits_list = typo_data['edits'].to_list()"
      ],
      "metadata": {
        "id": "EDesAxodqaSO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ignoring URLs\n",
        "2. Ignoring words inside brackets\n",
        "3. Ignoring non-english words"
      ],
      "metadata": {
        "id": "mvCQMK6Zp2MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "vocab = []\n",
        "word_matches = {}\n",
        "\n",
        "# Regex to check URL\n",
        "pattern = (\"((http|https)://)(www.)?\" +\n",
        "            \"[a-zA-Z0-9@:%._\\\\+~#?&//=]\" +\n",
        "            \"{2,256}\\\\.[a-z]\" +\n",
        "            \"{2,6}\\\\b([-a-zA-Z0-9@:%\" +\n",
        "            \"._\\\\+~#?&//=]*)\")\n",
        "     \n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "for edit in edits_list:\n",
        "    for text in edit:\n",
        "        tgt_sentence = text['tgt']['text'].lower()\n",
        "        src_sentence = text['src']['text'].lower()\n",
        "        src_words = tgt_words = []\n",
        "        for word in nltk.wordpunct_tokenize(tgt_sentence):\n",
        "            if word:\n",
        "                if re.search(pattern, word):\n",
        "                    break\n",
        "                # print(word)\n",
        "                chars = [chr for chr in word if (chr in alphabet) or \\\n",
        "                            chr in [\" \", \"_\"]]\n",
        "                # print(chars)\n",
        "                word = \"\".join(chars)\n",
        "                if word and len(word) > 1:\n",
        "                    tgt_words.append(word)\n",
        "                    if \"_\" not in word: \n",
        "                        vocab.append(word)\n",
        "\n",
        "        for word in nltk.wordpunct_tokenize(src_sentence):\n",
        "            if word:                \n",
        "                if re.search(pattern, word):\n",
        "                    break\n",
        "                chars = [chr for chr in word if (chr in alphabet) or \\\n",
        "                         chr in [\" \", \"_\"]]\n",
        "                word = \"\".join(chars)\n",
        "                if word and len(word) > 1:\n",
        "                    src_words.append(word)\n",
        "        word_list = [{tgt:src} for tgt, src in zip(tgt_words, src_words)]\n",
        "        if word_list:\n",
        "            for match in word_list:\n",
        "                word_matches.update(match)\n",
        "        "
      ],
      "metadata": {
        "id": "fZeFirCtrQtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6628c95a-6a65-43b3-88af-82c5ef512583"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa5ZtJwMsj1q",
        "outputId": "38fbd446-fcf5-4de0-c199-29f296443eef"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4492012"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the duplicates\n",
        "# vocab = list(set(vocab))"
      ],
      "metadata": {
        "id": "vyhkQvMPstnw"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRdzf6fVsulp",
        "outputId": "3d772841-d15a-446f-949d-b597951c1ec8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108969"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = random.randint(0, len(vocab) - 100)\n",
        "vocab[ind:ind + 100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr3tIs3_w_8k",
        "outputId": "5a273633-a30a-433e-958f-e55da944ae86"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kucaklar',\n",
              " 'datatabletype',\n",
              " 'todoservice',\n",
              " 'successes',\n",
              " 'ngdoc',\n",
              " 'arizona',\n",
              " 'streampipelinepersistentlogs',\n",
              " 'wikiproject',\n",
              " 'deviot',\n",
              " 'gltige',\n",
              " 'assertions',\n",
              " 'containerconfig',\n",
              " 'dua',\n",
              " 'fragmentation',\n",
              " 'scpbus',\n",
              " 'graphdef',\n",
              " 'template',\n",
              " 'structures',\n",
              " 'marston',\n",
              " 'aggravate',\n",
              " 'ki',\n",
              " 'logon',\n",
              " 'isarray',\n",
              " 'buildsystem',\n",
              " 'minimal',\n",
              " 'fling',\n",
              " 'selecthero',\n",
              " 'influences',\n",
              " 'harmonics',\n",
              " 'kullanlabilir',\n",
              " 'vconnection',\n",
              " 'simonboulier',\n",
              " 'serviceaccountcredentials',\n",
              " 'nofork',\n",
              " 'amazonsfullaccess',\n",
              " 'gollum',\n",
              " 'trfk',\n",
              " 'chance',\n",
              " 'sebastienros',\n",
              " 'recognizing',\n",
              " 'solucionar',\n",
              " 'extractimagefilter',\n",
              " 'chicagoboss',\n",
              " 'reactquill',\n",
              " 'horizontallayout',\n",
              " 'propagating',\n",
              " 'cranelift',\n",
              " 'stackalloc',\n",
              " 'controlplane',\n",
              " 'gtie',\n",
              " 'outcolor',\n",
              " 'braintreefragment',\n",
              " 'clv',\n",
              " 'framedata',\n",
              " 'demoed',\n",
              " 'tokyo',\n",
              " 'vuejs',\n",
              " 'hateoas',\n",
              " 'purely',\n",
              " 'note',\n",
              " 'fazem',\n",
              " 'multicasting',\n",
              " 'packageservice',\n",
              " 'metatada',\n",
              " 'stimodeltest',\n",
              " 'featuredjobitem',\n",
              " 'vrei',\n",
              " 'markup',\n",
              " 'gluonts',\n",
              " 'rpsystembroadcastpickerview',\n",
              " 'maintable',\n",
              " 'remotechrome',\n",
              " 'indirekt',\n",
              " 'shadowoffsetx',\n",
              " 'authenticationtableviewcontroller',\n",
              " 'theory',\n",
              " 'nicira',\n",
              " 'unconfigured',\n",
              " 'bisection',\n",
              " 'bezig',\n",
              " 'dbmss',\n",
              " 'ecosystem',\n",
              " 'setinterval',\n",
              " 'crowned',\n",
              " 'gitcredentialstore',\n",
              " 'executiondescriptor',\n",
              " 'bach',\n",
              " 'currentnodename',\n",
              " 'textlabel',\n",
              " 'jnusta',\n",
              " 'ungit',\n",
              " 'datahsheet',\n",
              " 'hacl',\n",
              " 'nemeth',\n",
              " 'openxc',\n",
              " 'adjusting',\n",
              " 'noughties',\n",
              " 'componenttorender',\n",
              " 'hastily',\n",
              " 'anglebars']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"github_typo_vocab.txt\", \"w\") as f:\n",
        "    for v in vocab:\n",
        "        f.write(v)\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "HxeUWgWWEhMW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation\n",
        "Dataset had urls, non-english words and others noises. Removed in preprocessing."
      ],
      "metadata": {
        "id": "pUnJDyjRchtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSFT spell correction dataset\n",
        "\n",
        "https://www.microsoft.com/en-us/download/details.aspx?id=52418  \n",
        "https://download.microsoft.com/download/B/8/E/B8E6EF6B-7D0B-456C-A774-D9E454765EFC/MSR%20Spelling%20Correction%20Data.zip"
      ],
      "metadata": {
        "id": "12jx4tDgy3Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.microsoft.com/download/B/8/E/B8E6EF6B-7D0B-456C-A774-D9E454765EFC/MSR%20Spelling%20Correction%20Data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcZxZ29ayv7b",
        "outputId": "10358844-f052-4a81-e0a2-d6f8aae63e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-19 05:50:41--  https://download.microsoft.com/download/B/8/E/B8E6EF6B-7D0B-456C-A774-D9E454765EFC/MSR%20Spelling%20Correction%20Data.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.60.85.2, 2600:1408:9000:6ac::317f, 2600:1408:9000:68a::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.60.85.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203875 (199K) [application/octet-stream]\n",
            "Saving to: ‘MSR Spelling Correction Data.zip’\n",
            "\n",
            "MSR Spelling Correc 100%[===================>] 199.10K  1.03MB/s    in 0.2s    \n",
            "\n",
            "2022-10-19 05:50:42 (1.03 MB/s) - ‘MSR Spelling Correction Data.zip’ saved [203875/203875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'MSR Spelling Correction Data.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdUFrMmDzFCJ",
        "outputId": "c8d1e294-bb54-4b71-aa99-c7688cd0596c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  MSR Spelling Correction Data.zip\n",
            "  inflating: MSR Spelling Correction Data.rtf  \n",
            "  inflating: ja_keystroke_pairs.sorted.txt  \n",
            "  inflating: en_keystroke_pairs.sorted.txt  \n",
            "  inflating: README.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOAJ3E_zMwH",
        "outputId": "0409b24c-cd9a-4a00-902b-f1c59c32e2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " big.txt\t\t\t  'MSR Spelling Correction Data.rtf'\n",
            " en_keystroke_pairs.sorted.txt\t  'MSR Spelling Correction Data.zip'\n",
            " github-typo-corpus.v1.0.0.jsonl   README.txt\n",
            " ja_keystroke_pairs.sorted.txt\t   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional Approach based spell correction\n"
      ],
      "metadata": {
        "id": "Otz21LS6m26h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Peter Norvig's algorithm"
      ],
      "metadata": {
        "id": "n2CapNqIAr-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations involved**\n",
        "\n",
        "1. Finding mispelled words based on a vocabulary of correct words\n",
        "2. Getting the relevant words based on edit distance (INSERT, DELETE, SWAP, REPLACE)\n",
        "3. Removing the words that are not n vocabulary and creating candidates.\n",
        "4. Choosing most likely candidate based on probability score.   \n",
        "**Probability p(w) = word count c(w) / total no. of words in the corpus t**"
      ],
      "metadata": {
        "id": "Wcb1Y9iPm-ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://norvig.com/big.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceFjtJuGfkpq",
        "outputId": "38fe2856-8c9c-4431-909f-3463ce3fadeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-19 04:54:26--  https://norvig.com/big.txt\n",
            "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
            "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6488666 (6.2M) [text/plain]\n",
            "Saving to: ‘big.txt’\n",
            "\n",
            "big.txt             100%[===================>]   6.19M  18.3MB/s    in 0.3s    \n",
            "\n",
            "2022-10-19 04:54:27 (18.3 MB/s) - ‘big.txt’ saved [6488666/6488666]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"big.txt\", 'r') as f:\n",
        "    data = f.read()"
      ],
      "metadata": {
        "id": "47b8K6lkfqde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "L1k1lJjdfxoG",
        "outputId": "aaf4ff03-90fc-4c09-a305-3a4e73e0d842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in our series by Sir Arthur Conan Doyle)\\n\\nCopyright laws are changing all over the world. Be sure to check the\\ncopyright laws for your country before downloading or redistributing\\nthis or any other Project Gutenberg eBook.\\n\\nThis header should be the first thing seen when viewing this Project\\nGutenberg file.  Please do not remove it.  Do not change or edit the\\nheader without written permission.\\n\\nPlease read the \"legal small print,\" and other information about the\\neBook and Project Gutenberg at the bottom of this file.  Included is\\nimportant information about your specific rights and restrictions in\\nhow the file may be used.  You can also find out about how to make a\\ndonation to Project Gutenberg, and how to get involved.\\n\\n\\n**Welcome To The World of Free Plain Vanilla Electronic Texts**\\n\\n**eBooks Readable By Both Humans and By Computers, Since 1971**\\n\\n*****These eBooks Were Prepared By Thousan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "⚡ Below code is taken from Peter Norvig's Algorithm for spelling correction.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6OLNbEFghdZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Spelling Corrector in Python 3; see http://norvig.com/spell-correct.html\n",
        "\n",
        "Copyright (c) 2007-2016 Peter Norvig\n",
        "MIT license: www.opensource.org/licenses/mit-license.php\n",
        "\"\"\"\n",
        "\n",
        "# Spelling Corrector \n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('big.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    c = candidates(word)\n",
        "    return max(c, key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
      ],
      "metadata": {
        "id": "hGKOfQLfxkd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing \n",
        "\n",
        "# def edits1(word):\n",
        "#     \"All edits that are one edit away from `word`.\"\n",
        "#     letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "#     print(\"splits: \", splits)\n",
        "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "#     print(\"deletes: \", deletes)\n",
        "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "#     print(\"transposes: \", transposes)\n",
        "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "#     print(\"replaces: \", replaces)\n",
        "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "#     print(\"inserts: \", inserts)\n",
        "\n",
        "#     return set(deletes + transposes + replaces + inserts)\n",
        "    \n",
        "# edits1('spling')"
      ],
      "metadata": {
        "id": "i51lgdltg7DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[correction(word) for word in '\"connect (host, port, anchor_amount): opens a channel with another eclair or lightningd instance\", '.split()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMyKtEbqgdOq",
        "outputId": "f7c3bee1-b8fc-45a9-da1b-e744f9e42dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['connect',\n",
              " 'host',\n",
              " 'ports',\n",
              " 'anchor_amount):',\n",
              " 'opens',\n",
              " 'a',\n",
              " 'channel',\n",
              " 'with',\n",
              " 'another',\n",
              " 'clair',\n",
              " 'or',\n",
              " 'lightning',\n",
              " 'instance']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Quite a few people went ahead and they bought their owninfrastructure and now they rent the services to other people, and when you talk about this infrastructurethe, quite a few people out there who are actually providingthese cloud services to different peopleacross the globe.\"\n",
        "corrected_words = []\n",
        "for word in sentence.split():\n",
        "    corrected_words.append(correction(word))\n",
        "print(\" \".join(corrected_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59EBmO_p2Iz7",
        "outputId": "a915457b-3274-47fb-b3fe-2cfa11628e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quite a few people went ahead and they bought their owninfrastructure and now they rent the services to other people and when you talk about this infrastructurethe, quite a few people out there who are actually providingthese cloud services to different peopleacross the globe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation\n",
        "Each singe word will be evaluated and word segmentation for example \"owninfrastruture\" is not spell corrected as candidates available. And it is slow as it looks for all the edits in a word.  "
      ],
      "metadata": {
        "id": "sFhyriW26i_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Peter-Norvig - Using custom vocab created from github typo corpus"
      ],
      "metadata": {
        "id": "Aiy2R-NEFBPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Spelling Corrector in Python 3; see http://norvig.com/spell-correct.html\n",
        "\n",
        "Copyright (c) 2007-2016 Peter Norvig\n",
        "MIT license: www.opensource.org/licenses/mit-license.php\n",
        "\"\"\"\n",
        "\n",
        "# Spelling Corrector \n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('github_typo_vocab.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    c = candidates(word)\n",
        "    return max(c, key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
      ],
      "metadata": {
        "id": "S_buA0b6E5eb"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(edits_list)-1)\n",
        "\n",
        "for edit in edits_list[idx:idx+1]:\n",
        "    for text in edit:\n",
        "        src_sentence = text['src']['text'].lower()\n",
        "src_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9h2agKwiGD0F",
        "outputId": "7f4bcfc1-f700-4792-c547-884b73195f74"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the `servicebroker` has a new `fatal` method. if you call it, you can log message with `fatal` level and exit the process with code `2`.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "sentence = src_sentence\n",
        "corrected_words = []\n",
        "for word in nltk.wordpunct_tokenize(sentence.strip()):\n",
        "    corrected_words.append(correction(word))\n",
        "print(\" \".join(corrected_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxWCuWboF0RT",
        "outputId": "a59f91d2-cce3-437c-bd61-f98499c4631d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the to servicebroker to has as new to fatal to method to if you call it to you can log message with to fatal to level and exit the process with code to to to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Symspell approach"
      ],
      "metadata": {
        "id": "t1D9yY74AxrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install symspellpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZAMkNdvpZev",
        "outputId": "7b04c668-cf66-4227-aad4-45f80d8fca89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting symspellpy\n",
            "  Downloading symspellpy-6.7.6-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 12.9 MB/s \n",
            "\u001b[?25hCollecting editdistpy>=0.1.3\n",
            "  Downloading editdistpy-0.1.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 52.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: editdistpy, symspellpy\n",
            "Successfully installed editdistpy-0.1.3 symspellpy-6.7.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "from symspellpy import SymSpell\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
        ")\n",
        "bigram_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
        ")\n",
        "# term_index is the column of the term and count_index is the\n",
        "# column of the term frequency\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)"
      ],
      "metadata": {
        "id": "f8wzYPrGpL-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7294de-4789-4bf4-e612-0394e66dcd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Quite a fw people 45 went ahead and they buought their owninfrastructure and now they rent the services to other people, and when you talk about this infrastructurethe, quite a few people out there who are actually providingthese cloud services to different peopleacross the globe.\"\n",
        "suggestions = sym_spell.lookup_compound(text, max_edit_distance=2, \n",
        "                                        ignore_non_words=True, transfer_casing=True)\n",
        "for suggestion in suggestions:\n",
        "    print(suggestion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHlrAaM5pzOs",
        "outputId": "0d015e6e-1894-4421-bec4-b2608acc737f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quite a few people 45 went ahead and they brought their own infrastructure and now they rent the services to other people and when you talk about this infrastructure the quite a few people out there who are actually providing these cloud services to different people across the globe, 9, 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(suggestion.term)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q21K-ABKqnke",
        "outputId": "c9c7ffbf-e10c-4f46-ed75-c3dd50ede68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quite a few people 45 went ahead and they brought their own infrastructure and now they rent the services to other people and when you talk about this infrastructure the quite a few people out there who are actually providing these cloud services to different people across the globe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation\n",
        "Word segmentation is also possible with this approach of using n-gram words as a dictionary to lookup and verify."
      ],
      "metadata": {
        "id": "O-eOyeKa_0ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWizK8n195Mo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}